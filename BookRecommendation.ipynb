{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nx4JfR_Urqg"
      },
      "source": [
        "# **Clone Git Repository**\n",
        "\n",
        "---\n",
        "\n",
        "Clone git agar dapat load data langsung dari git repository. Dataset yang digunakan didapat kan dari kaggle: https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset?select=Books.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcG8m5-rGChW"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/ziszz/book-recommendation.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rH9NUo0U6HS"
      },
      "source": [
        "# **Import library yang diperlukan**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPVKUwsIE552"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import glob\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from zipfile import ZipFile\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADxTjV1sVCwr"
      },
      "source": [
        "# **Data Loading**\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHPG-BqxFAMX"
      },
      "outputs": [],
      "source": [
        "books = pd.read_csv('/content/book-recommendation/datasets/Books.csv', encoding='utf-8')\n",
        "ratings = pd.read_csv('/content/book-recommendation/datasets/Ratings.csv', encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWq_0Ju9FDWa"
      },
      "outputs": [],
      "source": [
        "books"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naquyVoNFFEM"
      },
      "outputs": [],
      "source": [
        "ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnbLr_BkVajC"
      },
      "source": [
        "# **Exploratory Data**\n",
        "\n",
        "---\n",
        "\n",
        "## Variabel-variabel pada dataset adalah sebagai berikut:\n",
        "\n",
        "### **Books.csv**\n",
        "  * `ISBN`: Kode pengidentifikasian buku yang bersifat unik.\n",
        "  * `Book-Title`: Judul Buku.\n",
        "  * `Book-Author`: Nama pengarang buku.\n",
        "  * `Publisher`: Pihak penerbit buku.\n",
        "  * `Image-URL-S`: URL yang menautkan ke gambar sampul berukuran small.\n",
        "  * `Image-URL-M`: URL yang menautkan ke gambar sampul berukuran medium.\n",
        "  * `Image-URL-L`: URL yang menautkan ke gambar sampul berukuran large.\n",
        "\n",
        "### **Ratings.csv**\n",
        "  * `User-ID`: Nomer unik user yang memberikan rating.\n",
        "  * `ISBN`: Kode pengidentifikasian buku yang bersifat unik.\n",
        "  * `Book-Rating`: Skor dari rating yang diberikan.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "572W8sbxYYBb"
      },
      "source": [
        "## **Menghitung jumlah Buku, User dan Rating**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BluEdltXFGmp"
      },
      "outputs": [],
      "source": [
        "print('Jumlah data buku: ', len(books['ISBN'].unique()))\n",
        "print('Jumlah data user yang memberikan rating: ', len(ratings['User-ID'].unique()))\n",
        "print('Jumlah data rating pada buku: ', len(ratings['ISBN'].unique()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-J6CfhhZBeA"
      },
      "source": [
        "## **Mendapatkan info pada data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gGg190QFIcI"
      },
      "outputs": [],
      "source": [
        "books.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zS7ZoN3yZWcN"
      },
      "source": [
        "Terlihat dari data buku di atas. Semua kolom data memiliki type data object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mCSzUdS0FJ2_"
      },
      "outputs": [],
      "source": [
        "ratings.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd0og85_Zuqd"
      },
      "source": [
        "Sedangkan, untuk data rating terdapat 2 tipe pada data yaitu numerik (int64) dan object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgXIgF4xFNgH"
      },
      "outputs": [],
      "source": [
        "book_list = books['Book-Title'].value_counts().keys()\n",
        "jumlah = books['Book-Title'].value_counts()\n",
        "\n",
        "book_count = pd.DataFrame({'Book-Title': book_list, 'Jumlah': jumlah}).reset_index(drop=True)\n",
        "book_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpPshsDpsWQO"
      },
      "source": [
        "Pada data terdapat 242135 data unik judul buku. Terlihat bahwa ada beberapa baris dalam data buku memiliki judul buku yang sama. Oleh karena itu, data duplikat perlu dihapus dan hanya memilih baris dengan Judul Buku yang unik."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p2uB1BYFFSb0"
      },
      "outputs": [],
      "source": [
        "rating_list = ratings['Book-Rating'].value_counts().keys()\n",
        "jumlah = ratings['Book-Rating'].value_counts()\n",
        "\n",
        "rating_count = pd.DataFrame({'Ratings': rating_list, 'Jumlah': jumlah}).reset_index(drop=True)\n",
        "rating_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3ioZTgruM3n"
      },
      "source": [
        "Dari output di atas, diketahui bahwa nilai maksimum rating adalah 10 dan nilai minimumnya adalah 0. Artinya, skala rating berkisar antara 0 hingga 10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6reGWl9ZpSNB"
      },
      "source": [
        "## **Memeriksa missing value**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wavr7TnVFLS7"
      },
      "outputs": [],
      "source": [
        "books.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C814r9FbFMxG"
      },
      "outputs": [],
      "source": [
        "ratings.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Jika dilihat dari data buku dan data rating di atas. Terdapat sedikit missing value pada data buku, sedangkan pada data rating tidak memiliki missing value."
      ],
      "metadata": {
        "id": "ZG240dmTOcTp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO6VxkbPq952"
      },
      "source": [
        "# **Content-Based Filtering**\n",
        "---\n",
        "## **Data Preparation**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Menghapus data yang tidak diperlukan**\n",
        "Sistem rekomendasi ini hanya memerlukan data author dan rating sebagai fitur untuk model. Beberapa kolom data seperti `'Year-Of-Publication', 'Publisher', 'Image-URL-M', 'Image-URL-L'` tidak akan digunakan untuk sistem rekomendasi ini. Jadi data tersebut bisa dihapus."
      ],
      "metadata": {
        "id": "yNu3PvXGWYN1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXtNb2XHLl6u"
      },
      "outputs": [],
      "source": [
        "unused_columns = ['Year-Of-Publication', 'Publisher', 'Image-URL-M', 'Image-URL-L']\n",
        "books.drop(unused_columns, axis=1, inplace=True)\n",
        "books"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Menggabungkan data buku dan rating**"
      ],
      "metadata": {
        "id": "Rg6ACrjMG8Kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_ratings = ratings.merge(books,on='ISBN')\n",
        "new_ratings = new_ratings.groupby('Book-Title').sum()['Book-Rating'].reset_index()\n",
        "new_ratings.rename(columns={'Book-Rating':'Num-Ratings'}, inplace=True)"
      ],
      "metadata": {
        "id": "6ml0duN0CHSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mw8wXvhGKN5S"
      },
      "outputs": [],
      "source": [
        "new_books = pd.DataFrame({'Book-Title': books['Book-Title'].unique()})\n",
        "new_books = pd.merge(new_books, new_ratings, on='Book-Title', how='left')\n",
        "new_books = new_books.merge(books,on='Book-Title').drop_duplicates('Book-Title')\n",
        "new_books"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v9XEEB74voe"
      },
      "source": [
        "### **Mengatasi missing value**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IO_xNCZUMJw5"
      },
      "outputs": [],
      "source": [
        "new_books.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_jiUfgZM_XH"
      },
      "outputs": [],
      "source": [
        "new_books = new_books.dropna()\n",
        "new_books.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiXtGMZw495C"
      },
      "outputs": [],
      "source": [
        "new_books.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjgB7n2y8ibo"
      },
      "source": [
        "### **Menyeleksi data**\n",
        "Data yang akan digunakan yaitu data buku dengan total skor rating dari tiap buku di atas 500. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_books = new_books[new_books['Num-Ratings'] > 50]\n",
        "final_books.drop(['ISBN', 'Num-Ratings'], axis=1, inplace=True)\n",
        "final_books"
      ],
      "metadata": {
        "id": "nMLklL87C6Vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqmRAOWT5_Cz"
      },
      "source": [
        "## **Model Development**\n",
        "### **Tfid Vectorizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN0l3F0v54ZT"
      },
      "outputs": [],
      "source": [
        "data = final_books\n",
        "data.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzhxVUDt6JuE"
      },
      "outputs": [],
      "source": [
        "tfid = TfidfVectorizer(token_pattern=r\"(?u)\\b\\w\\w+\\b\\s+\\w+\")\n",
        "tfid.fit(data['Book-Author']) \n",
        "\n",
        "tfid.get_feature_names() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbqwN46T88Tb"
      },
      "source": [
        "### **Transformasi data kedalam bentuk matriks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-OV_vMP6VIn"
      },
      "outputs": [],
      "source": [
        "tfidf_matrix = tfid.fit_transform(data['Book-Author']) \n",
        "tfidf_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VuKcdgM9OWt"
      },
      "source": [
        "### **Menghitung Cosine Similarity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJgruWTp8OO5"
      },
      "outputs": [],
      "source": [
        "cosine_sim = cosine_similarity(tfidf_matrix) \n",
        "cosine_sim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_sim_df = pd.DataFrame(cosine_sim, index=data['Book-Title'], columns=data['Book-Title'])"
      ],
      "metadata": {
        "id": "Q3g9KoSXIUQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Mendapatkan rekomendasi buku**\n",
        "Mendapatkan rekomendasi buku berdasarkan author yang sama dengan buku yang telah dibaca oleh user."
      ],
      "metadata": {
        "id": "BPNjDBurIAMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def book_recommendations(book_name, similarity_data=cosine_sim_df, items=data, k=5):\n",
        "  index = similarity_data[book_name].to_numpy().argpartition(range(-1, -(k+1), -1))[::-1]\n",
        "  closest = similarity_data.columns[index[:k+2]]\n",
        "  closest = closest.drop(book_name, errors='ignore')\n",
        "\n",
        "  return pd.DataFrame(closest).merge(items).head(k)"
      ],
      "metadata": {
        "id": "czpIUWQ2H-RB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_recommendations('She\\'s Come Undone (Oprah\\'s Book Club (Paperback))')"
      ],
      "metadata": {
        "id": "z9rtDrbxJqdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Collaborative Filtering**\n",
        "\n",
        "---\n",
        "\n",
        "## **Data Preparation**"
      ],
      "metadata": {
        "id": "TN0xm4C2PRNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Menggabungkan data buku dan rating**\n",
        "Tidak seperti pada teknik Content-Based Filtering. Data yang digunakan di teknik Collaborative Filtering kali ini tidak memerlukan data `Book-Author, Num-Ratings,` dan `ISBN`. Sebab pada teknik ini hanya menggunakan rating sebagai acuan sistem rekomendasi."
      ],
      "metadata": {
        "id": "PDUX0RHnZKeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = ratings\n",
        "df = df.merge(new_books, on='ISBN')\n",
        "df.drop(['Num-Ratings', 'Book-Author', 'ISBN'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "4rzXU9iVPYvw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Menyandikan fitur**\n",
        "Membuat penyandian untuk fitur `User-ID` dan `Book-Title` menjadi dalam bentuk index"
      ],
      "metadata": {
        "id": "DTF9tocWamKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_ids = df['User-ID'].unique().tolist()\n",
        "user2encoded = {x: i for i, x in enumerate(user_ids)}\n",
        "encoded2user = {i: x for i, x in enumerate(user_ids)}"
      ],
      "metadata": {
        "id": "kPMlOSmSTmGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_title = df['Book-Title'].unique().tolist()\n",
        "book2encoded = {x: i for i, x in enumerate(book_title)}\n",
        "encoded2book = {i: x for i, x in enumerate(book_title)}"
      ],
      "metadata": {
        "id": "SbNmK-s_YODq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['User-Encoded'] = df['User-ID'].map(user2encoded)\n",
        "df['Book-Encoded'] = df['Book-Title'].map(book2encoded)"
      ],
      "metadata": {
        "id": "6ldC98x7YxxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_users = len(user2encoded)\n",
        "print(num_users)\n",
        " \n",
        "num_books = len(encoded2book)\n",
        "print(num_books)\n",
        "\n",
        "df['Book-Rating'] = df['Book-Rating'].values.astype(np.float32)\n",
        " \n",
        "min_rating = min(df['Book-Rating'])\n",
        "max_rating = max(df['Book-Rating'])\n",
        "\n",
        "print(f'Number of User: {num_users}, Number of Books: {num_books}, Min Rating: {min_rating}, Max Rating: {max_rating}')"
      ],
      "metadata": {
        "id": "Fn-xZODqZIoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "jeYLn2B2fZw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Normalisasi data rating**\n",
        "Melakukan transformasi pada data fitur `Book-Rating`. MinMaxScaler mentransformasikan fitur dengan menskalakan setiap fitur ke rentang tertentu. Library ini menskalakan dan mentransformasikan setiap fitur secara individual sehingga berada dalam rentang yang diberikan pada set pelatihan, pada library ini memiliki range default antara nol dan satu."
      ],
      "metadata": {
        "id": "wcpZ_4eNbQ28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = df[['User-Encoded', 'Book-Encoded']].values\n",
        "y = df['Book-Rating'].values\n",
        "y = y.reshape(-1, 1)"
      ],
      "metadata": {
        "id": "J-3npReDbw8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "norm_y = scaler.fit_transform(y)\n",
        "norm_y = norm_y.reshape(1, -1)[0]"
      ],
      "metadata": {
        "id": "-gniIyl_bU3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Split dataset**"
      ],
      "metadata": {
        "id": "diP7VbpobEb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x, norm_y, test_size=0.2, random_state=123)"
      ],
      "metadata": {
        "id": "YM3jy7RKadQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Membuat data pipeline**"
      ],
      "metadata": {
        "id": "uE55Bvz7f6ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(x, y, batch_size, buffer_size=None, shuffle=True):\n",
        "  ds = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size)\n",
        "\n",
        "  ds = ds.batch(batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "  return ds"
      ],
      "metadata": {
        "id": "ymOfQQd6gMaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "buffer_size = len(x)\n",
        "\n",
        "train_ds = create_dataset(x_train, y_train, batch_size, buffer_size)\n",
        "val_ds = create_dataset(x_val, y_val, batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "1tCN-dHZgyf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Development**\n",
        "### **Membuat model**"
      ],
      "metadata": {
        "id": "TBBiXFPgdKLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RecommenderNet(tf.keras.Model):\n",
        "  def __init__(self, num_users, num_books, embedding_size, **kwargs):\n",
        "    super(RecommenderNet, self).__init__(**kwargs)\n",
        "\n",
        "    self.num_users = num_users\n",
        "    self.num_books = num_books\n",
        "    self.embedding_size = embedding_size\n",
        "    self.user_embedding = layers.Embedding(\n",
        "        num_users,\n",
        "        embedding_size,\n",
        "        embeddings_initializer='he_normal',\n",
        "        embeddings_regularizer=keras.regularizers.l2(1e-3),\n",
        "    )\n",
        "    self.user_bias = layers.Embedding(num_users, 1)\n",
        "    self.books_embedding = layers.Embedding(\n",
        "        num_books,\n",
        "        embedding_size,\n",
        "        embeddings_initializer='he_normal',\n",
        "        embeddings_regularizer=keras.regularizers.l2(1e-3),\n",
        "    )\n",
        "    self.books_bias = layers.Embedding(num_books, 1)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    user_vector = self.user_embedding(inputs[:, 0])\n",
        "    user_bias = self.user_bias(inputs[:, 0])\n",
        "    books_vector = self.books_embedding(inputs[:, 1])\n",
        "    books_bias = self.books_bias(inputs[:, 1])\n",
        "\n",
        "    dot_user_books = tf.tensordot(user_vector, books_vector, 2)\n",
        "\n",
        "    x = dot_user_books + user_bias + books_bias\n",
        "\n",
        "    return tf.nn.sigmoid(x)"
      ],
      "metadata": {
        "id": "52fgIQWqcvK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 64\n",
        "\n",
        "model = RecommenderNet(num_users, num_books, embedding_size)\n",
        "model.compile(\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        ")"
      ],
      "metadata": {
        "id": "g_pq5roGdEHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Melatih model**"
      ],
      "metadata": {
        "id": "m6Tzl55oekBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs = 10,\n",
        "    validation_data = val_ds,\n",
        "    verbose=1,\n",
        ")"
      ],
      "metadata": {
        "id": "cPPEcv4Cd1ij"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "BookRecommendation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPgHUDQrGeLgfhPmQK1zrHF"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}